{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f270bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 16:23:23.092350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 16:23:23.300272: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-28 16:23:23.349580: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-28 16:23:25.805389: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-11.2-el8-x86_64/lib64:/software/cuda-11.2-el8-x86_64/extras/CUPTI/lib64:/software/cuda-11.2-el8-x86_64/lib64:/software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64\n",
      "2023-03-28 16:23:25.805461: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-11.2-el8-x86_64/lib64:/software/cuda-11.2-el8-x86_64/extras/CUPTI/lib64:/software/cuda-11.2-el8-x86_64/lib64:/software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64\n",
      "2023-03-28 16:23:25.805467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import json\n",
    "import munch\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import munch\n",
    "workdir = os.getcwd()+\"/\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_device_details(gpus[0])\n",
    "sys.path.insert(0, workdir+'/DeepBSDE')\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3g}'.format\n",
    "sns.set(font_scale = 1.0, rc={\"grid.linewidth\": 1,'grid.color': '#b0b0b0', 'axes.edgecolor': 'black',\"lines.linewidth\": 3.0}, style = 'whitegrid')\n",
    "\n",
    "# import DGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1fbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    # constructor/initializer function (automatically called when new instance of class is created)\n",
    "    def __init__(self, output_dim, input_dim, trans1 = \"tanh\", trans2 = \"tanh\"):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim (int):       dimensionality of input data\n",
    "            output_dim (int):      number of outputs for LSTM layers\n",
    "            trans1, trans2 (str):  activation functions used inside the layer; \n",
    "                                   one of: \"tanh\" (default), \"relu\" or \"sigmoid\"\n",
    "        \n",
    "        Returns: customized Keras layer object used as intermediate layers in DGM\n",
    "        '''        \n",
    "        \n",
    "        # create an instance of a Layer object (call initialize function of superclass of LSTMLayer)\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        \n",
    "        # add properties for layer including activation functions used inside the layer  \n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        if trans1 == \"tanh\":\n",
    "            self.trans1 = tf.nn.tanh\n",
    "        elif trans1 == \"relu\":\n",
    "            self.trans1 = tf.nn.relu\n",
    "        elif trans1 == \"sigmoid\":\n",
    "            self.trans1 = tf.nn.sigmoid\n",
    "        \n",
    "        if trans2 == \"tanh\":\n",
    "            self.trans2 = tf.nn.tanh\n",
    "        elif trans2 == \"relu\":\n",
    "            self.trans2 = tf.nn.relu\n",
    "        elif trans2 == \"sigmoid\":\n",
    "            self.trans2 = tf.nn.relu\n",
    "        \n",
    "        ### define LSTM layer parameters (use Xavier initialization)\n",
    "        # u vectors (weighting vectors for inputs original inputs x)\n",
    "        self.Uz = self.add_variable(\"Uz\", shape=[self.input_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Ug = self.add_variable(\"Ug\", shape=[self.input_dim ,self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Ur = self.add_variable(\"Ur\", shape=[self.input_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Uh = self.add_variable(\"Uh\", shape=[self.input_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        \n",
    "        # w vectors (weighting vectors for output of previous layer)        \n",
    "        self.Wz = self.add_variable(\"Wz\", shape=[self.output_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Wg = self.add_variable(\"Wg\", shape=[self.output_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Wr = self.add_variable(\"Wr\", shape=[self.output_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        self.Wh = self.add_variable(\"Wh\", shape=[self.output_dim, self.output_dim],\n",
    "                                    initializer = tf.keras.initializers.glorot_normal)\n",
    "        \n",
    "        # bias vectors\n",
    "        self.bz = self.add_variable(\"bz\", shape=[1, self.output_dim])\n",
    "        self.bg = self.add_variable(\"bg\", shape=[1, self.output_dim])\n",
    "        self.br = self.add_variable(\"br\", shape=[1, self.output_dim])\n",
    "        self.bh = self.add_variable(\"bh\", shape=[1, self.output_dim])\n",
    "    \n",
    "    \n",
    "    # main function to be called \n",
    "    def call(self, S, X):\n",
    "        '''Compute output of a LSTMLayer for a given inputs S,X .    \n",
    "\n",
    "        Args:            \n",
    "            S: output of previous layer\n",
    "            X: data input\n",
    "        \n",
    "        Returns: customized Keras layer object used as intermediate layers in DGM\n",
    "        '''   \n",
    "        \n",
    "        # compute components of LSTM layer output (note H uses a separate activation function)\n",
    "        Z = self.trans1(tf.add(tf.add(tf.matmul(X,self.Uz), tf.matmul(S,self.Wz)), self.bz))\n",
    "        G = self.trans1(tf.add(tf.add(tf.matmul(X,self.Ug), tf.matmul(S, self.Wg)), self.bg))\n",
    "        R = self.trans1(tf.add(tf.add(tf.matmul(X,self.Ur), tf.matmul(S, self.Wr)), self.br))\n",
    "        \n",
    "        H = self.trans2(tf.add(tf.add(tf.matmul(X,self.Uh), tf.matmul(tf.multiply(S, R), self.Wh)), self.bh))\n",
    "        \n",
    "        # compute LSTM layer output\n",
    "        S_new = tf.add(tf.multiply(tf.subtract(tf.ones_like(G), G), H), tf.multiply(Z,S))\n",
    "        \n",
    "        return S_new\n",
    "\n",
    "#%% Fully connected (dense) layer - modification of Keras layer class\n",
    "   \n",
    "class DenseLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    # constructor/initializer function (automatically called when new instance of class is created)\n",
    "    def __init__(self, output_dim, input_dim, transformation=None):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim:       dimensionality of input data\n",
    "            output_dim:      number of outputs for dense layer\n",
    "            transformation:  activation function used inside the layer; using\n",
    "                             None is equivalent to the identity map \n",
    "        \n",
    "        Returns: customized Keras (fully connected) layer object \n",
    "        '''        \n",
    "        \n",
    "        # create an instance of a Layer object (call initialize function of superclass of DenseLayer)\n",
    "        super(DenseLayer,self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        ### define dense layer parameters (use Xavier initialization)\n",
    "        # w vectors (weighting vectors for output of previous layer)\n",
    "        self.W = self.add_variable(\"W\", shape=[self.input_dim, self.output_dim],\n",
    "                                   initializer = tf.keras.initializers.glorot_normal)\n",
    "        \n",
    "        # bias vectors\n",
    "        self.b = self.add_variable(\"b\", shape=[1, self.output_dim])\n",
    "        \n",
    "        if transformation:\n",
    "            if transformation == \"tanh\":\n",
    "                self.transformation = tf.tanh\n",
    "            elif transformation == \"relu\":\n",
    "                self.transformation = tf.nn.relu\n",
    "        else:\n",
    "            self.transformation = transformation\n",
    "    \n",
    "    \n",
    "    # main function to be called \n",
    "    def call(self,X):\n",
    "        '''Compute output of a dense layer for a given input X \n",
    "\n",
    "        Args:                        \n",
    "            X: input to layer            \n",
    "        '''\n",
    "        \n",
    "        # compute dense layer output\n",
    "        S = tf.add(tf.matmul(X, self.W), self.b)\n",
    "                \n",
    "        if self.transformation:\n",
    "            S = self.transformation(S)\n",
    "        \n",
    "        return S\n",
    "\n",
    "#%% Neural network architecture used in DGM - modification of Keras Model class\n",
    "    \n",
    "class DGMNet(tf.keras.Model):\n",
    "    \n",
    "    # constructor/initializer function (automatically called when new instance of class is created)\n",
    "    def __init__(self, layer_width, n_layers, input_dim, final_trans=None):\n",
    "        '''\n",
    "        Args:\n",
    "            layer_width: \n",
    "            n_layers:    number of intermediate LSTM layers\n",
    "            input_dim:   spaital dimension of input data (EXCLUDES time dimension)\n",
    "            final_trans: transformation used in final layer\n",
    "        \n",
    "        Returns: customized Keras model object representing DGM neural network\n",
    "        '''  \n",
    "        \n",
    "        # create an instance of a Model object (call initialize function of superclass of DGMNet)\n",
    "        super(DGMNet,self).__init__()\n",
    "        \n",
    "        # define initial layer as fully connected \n",
    "        # NOTE: to account for time inputs we use input_dim+1 as the input dimensionality\n",
    "#         self.initial_layer = DenseLayer(layer_width, input_dim+1, transformation = \"tanh\")\n",
    "        self.initial_layer = DenseLayer(layer_width, input_dim, transformation = \"tanh\")\n",
    "        \n",
    "        # define intermediate LSTM layers\n",
    "        self.n_layers = n_layers\n",
    "        self.LSTMLayerList = []\n",
    "                \n",
    "        for _ in range(self.n_layers):\n",
    "#             self.LSTMLayerList.append(LSTMLayer(layer_width, input_dim+1))\n",
    "            self.LSTMLayerList.append(LSTMLayer(layer_width, input_dim))\n",
    "        \n",
    "        # define final layer as fully connected with a single output (function value)\n",
    "        self.final_layer = DenseLayer(1, layer_width, transformation = final_trans)\n",
    "    \n",
    "    \n",
    "    # main function to be called  \n",
    "    def call(self,X):\n",
    "        '''            \n",
    "        Args:\n",
    "            t: sampled time inputs \n",
    "            x: sampled space inputs\n",
    "\n",
    "        Run the DGM model and obtain fitted function value at the inputs (t,x)                \n",
    "        '''  \n",
    "        \n",
    "        # define input vector as time-space pairs\n",
    "#         X = tf.concat([t,x],1)\n",
    "\n",
    "        \n",
    "        # call initial layer\n",
    "        S = self.initial_layer.call(X)\n",
    "        \n",
    "        # call intermediate LSTM layers\n",
    "        for i in range(self.n_layers):\n",
    "            S = self.LSTMLayerList[i].call(S,X)\n",
    "        \n",
    "        # call final LSTM layers\n",
    "        result = self.final_layer.call(S)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.constant(0.002, dtype = tf.float64)\n",
    "phi1 = tf.constant(28.0, dtype = tf.float64)\n",
    "phi2 = tf.constant(28.0, dtype = tf.float64)\n",
    "beta1 = tf.constant(0.01, dtype = tf.float64)\n",
    "beta2 = tf.constant(0.01, dtype = tf.float64)\n",
    "eta1 = tf.constant(0.012790328319261378, dtype = tf.float64)\n",
    "eta2 = tf.constant(0.012790328319261378, dtype = tf.float64)\n",
    "a11 = tf.constant(0.014, dtype = tf.float64)\n",
    "a22 = tf.constant(0.013, dtype = tf.float64)\n",
    "alpha = tf.constant(0.1, dtype = tf.float64)\n",
    "scale = np.sqrt(1.754)\n",
    "sigma_k1 = tf.convert_to_tensor(scale*np.array([[.00477,               .0,   .0, .0]]), dtype = tf.float64)\n",
    "sigma_k2 = tf.convert_to_tensor(scale*np.array([[.0              , .00477,   .0, .0]]), dtype = tf.float64)\n",
    "sigma_z =  tf.convert_to_tensor(np.array([[.011*np.sqrt(.5)   , .011*np.sqrt(.5)   , .025, .0]]), dtype = tf.float64)\n",
    "sigma_s =  tf.convert_to_tensor(np.array([[.1*np.sqrt(.5)   , .1*np.sqrt(.5)   , .0, .1]]), dtype = tf.float64)\n",
    "\n",
    "clowerlim = tf.constant(0.0001, dtype = tf.float64)\n",
    "rho = tf.constant(1.0, dtype = tf.float64)\n",
    "gamma = tf.constant(8.0, dtype = tf.float64)\n",
    "kappa = tf.constant(2.0, dtype = tf.float64)\n",
    "zeta = tf.constant(0.5, dtype = tf.float64)\n",
    "wMin = tf.constant(-1., dtype = tf.float64)\n",
    "wMax = tf.constant(1., dtype = tf.float64)\n",
    "zMin = tf.constant(-1., dtype = tf.float64)\n",
    "zMax = tf.constant(1., dtype = tf.float64)\n",
    "vMin = tf.constant(0.001, dtype = tf.float64)\n",
    "vMax = tf.constant(1.999, dtype = tf.float64)\n",
    "\n",
    "\n",
    "params = {'delta':delta,\n",
    "         'phi1':phi1,\n",
    "         'phi2':phi2,\n",
    "         'beta1':beta1,\n",
    "         'beta2':beta2,\n",
    "         'eta1':eta1,\n",
    "         'eta2':eta2,\n",
    "         'a11':a11,\n",
    "         'a22':a22,\n",
    "         'alpha':alpha,\n",
    "         'sigma_k1':sigma_k1,\n",
    "         'sigma_k2':sigma_k2,\n",
    "         'sigma_z':sigma_z,\n",
    "         'sigma_s':sigma_s,\n",
    "         'rho':rho,\n",
    "         'gamma':gamma,\n",
    "         'kappa':kappa,\n",
    "         'zeta':zeta,\n",
    "         'wMin':wMin,\n",
    "         'wMax':wMax,\n",
    "         'zMin':zMin,\n",
    "         'zMax':zMax,\n",
    "         'vMin':vMin,\n",
    "         'vMax':vMax,\n",
    "         'clowerlim':clowerlim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e48561ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function \n",
    "def calder(func,W, Z, V):\n",
    "    X = tf.concat([W,Z,V], axis=1)\n",
    "    logXiE       = func(X)\n",
    "    \n",
    "    dW_logXiE     = tf.gradients(logXiE, W)[0];       dZ_logXiE     = tf.gradients(logXiE, Z)[0];       dV_logXiE     = tf.gradients(logXiE, V)[0]; \n",
    "    dW2_logXiE    = tf.gradients(dW_logXiE, W)[0];    dZ2_logXiE    = tf.gradients(dZ_logXiE, Z)[0];    dV2_logXiE    = tf.gradients(dV_logXiE, V)[0];  \n",
    "    dWdZ_logXiE   = tf.gradients(dW_logXiE, Z)[0];    dWdV_logXiE   = tf.gradients(dW_logXiE, V)[0];    dZdV_logXiE   = tf.gradients(dZ_logXiE, V)[0];   \n",
    "    \n",
    "    return dW_logXiE, dZ_logXiE, dV_logXiE, dW2_logXiE, dZ2_logXiE, dV2_logXiE, dWdZ_logXiE, dWdV_logXiE, dZdV_logXiE\n",
    "\n",
    "@tf.function \n",
    "def calvar(func, W, Z, V, params):\n",
    "    X = tf.concat([W,Z,V], axis=1)\n",
    "    logXiE       = func(X)\n",
    "    Vr, Vz, Vs, Vrr, Vzz, Vss, Vrz, Vrs, Vzs = calder(func, W, Z, V)\n",
    "\n",
    "    k1a = (1-params['zeta'] + params['zeta']*tf.exp(W*(1-params['kappa'])))**(1/(params['kappa']-1))\n",
    "    k2a = ((1-params['zeta'])*tf.exp(W*(params['kappa']-1)) + params['zeta'])**(1/(params['kappa']-1))\n",
    "\n",
    "    bb1 = (params['alpha'] - 1/params['phi1']*k1a-1/params['phi2']*k2a)\n",
    "    cc1 = params['delta']*k1a**2/params['phi1']/((1-params['zeta'])*k1a**(1-params['kappa'])-Vr) + params['delta']*k2a**2/params['phi2']/(params['zeta']*(k2a)**(1-params['kappa'])+Vr)\n",
    "    aa1 = -1\n",
    "    sqrt_test1 = bb1**2 - 4*aa1*cc1;\n",
    "    event_A = tf.cast((sqrt_test1 >= 0),tf.float64);\n",
    "\n",
    "    c_root_large = event_A * (-bb1 - tf.sqrt(event_A*sqrt_test1))/(2*aa1);\n",
    "    c_root_small = event_A * (-bb1 + tf.sqrt(event_A*sqrt_test1))/(2*aa1);\n",
    "    c_root_large = c_root_large*tf.cast(tf.math.greater(c_root_large,params['clowerlim']),tf.float64) + \\\n",
    "        params['clowerlim']*tf.ones([batchSize,1],tf.float64)*tf.cast(tf.math.less(c_root_large,params['clowerlim']),tf.float64)\n",
    "\n",
    "    d1_root = 1/params['phi1']-params['delta']*k1a/((1-params['zeta'])*k1a**(1-params['kappa'])-Vr)/params['phi1']/c_root_large\n",
    "    d2_root = 1/params['phi2']-params['delta']*k2a/(params['zeta']*(k2a)**(1-params['kappa'])+Vr)/params['phi2']/c_root_large\n",
    "\n",
    "    uu = params['delta']*tf.math.log(c_root_large)\n",
    "    mu_k1 = (d1_root - params['phi1']/2*d1_root**2) + params['beta1']*Z - eta1\n",
    "    mu_k2 = (d2_root - params['phi2']/2*d2_root**2) + params['beta2']*Z - eta2\n",
    "    mu_r = mu_k2 - mu_k1 - V/2*(tf.reduce_sum(params['sigma_k2']**2) - tf.reduce_sum(params['sigma_k1']**2))\n",
    "\n",
    "    dkadk1dk1 = (kappa-1)*(1-zeta)**2*(k1a)**(-2*kappa+2) - kappa*(1-zeta)*(k1a)**(-kappa+1)\n",
    "    dkadk1dk2 = (kappa-1)*zeta*(1-zeta)*(k1a)**(-kappa+1)*(k2a)**(-kappa+1)\n",
    "    dkadk2dk2 = (kappa-1)*zeta**2*(k2a)**(-2*kappa+2) - kappa*(1-zeta)*(k2a)**(-kappa+1)\n",
    "\n",
    "    mu_1 = mu_k1*(1-params['zeta'])*(k1a)**(1-params['kappa'])+ \\\n",
    "            mu_k2*(params['zeta'])*(k2a)**(1-params['kappa'])+ \\\n",
    "            V/2*(tf.reduce_sum(params['sigma_k1']**2)*dkadk1dk1 + \\\n",
    "                                                tf.reduce_sum(params['sigma_k2']**2)*dkadk2dk2 + \\\n",
    "                                                2*tf.reduce_sum(params['sigma_k1']*params['sigma_k2'])*dkadk1dk2)\n",
    "\n",
    "    zdrift = -params['a11']*Z\n",
    "    sdrift = -params['a22']*(V-1)\n",
    "\n",
    "    h1 = params['sigma_k1'][0,0]*(1-params['zeta'])*(k1a)**(1-params['kappa'])+ params['sigma_k2'][0,0]*(params['zeta'])*(k2a)**(1-params['kappa'])+\\\n",
    "        (params['sigma_k2'][0,0]-params['sigma_k1'][0,0])*Vr + params['sigma_z'][0,0]*Vz+params['sigma_s'][0,0]*Vs\n",
    "    h2 = params['sigma_k1'][0,1]*(1-params['zeta'])*(k1a)**(1-params['kappa'])+ params['sigma_k2'][0,1]*(params['zeta'])*(k2a)**(1-params['kappa'])+\\\n",
    "        (params['sigma_k2'][0,1]-params['sigma_k1'][0,1])*Vr + params['sigma_z'][0,1]*Vz+params['sigma_s'][0,1]*Vs\n",
    "    hz = params['sigma_k1'][0,2]*(1-params['zeta'])*(k1a)**(1-params['kappa'])+ params['sigma_k2'][0,2]*(params['zeta'])*(k2a)**(1-params['kappa'])+\\\n",
    "        (params['sigma_k2'][0,2]-params['sigma_k1'][0,2])*Vr + params['sigma_z'][0,2]*Vz+params['sigma_s'][0,2]*Vs\n",
    "    hs = params['sigma_k1'][0,3]*(1-params['zeta'])*(k1a)**(1-params['kappa'])+ params['sigma_k2'][0,3]*(params['zeta'])*(k2a)**(1-params['kappa'])+\\\n",
    "        (params['sigma_k2'][0,3]-params['sigma_k1'][0,3])*Vr + params['sigma_z'][0,3]*Vz+params['sigma_s'][0,3]*Vs\n",
    "\n",
    "    penalty_term = (1-params['gamma'])*V*(h1**2 + h2**2 + hz**2 + hs**2)\n",
    "    uu = uu + penalty_term + mu_1\n",
    "    t1 = tf.reduce_sum((params['sigma_k2']-params['sigma_k1'])**2)\n",
    "    t2 = tf.reduce_sum((params['sigma_k2']-params['sigma_k1'])*params['sigma_z'])*2\n",
    "    t3 = tf.reduce_sum(params['sigma_z']**2)\n",
    "\n",
    "    t4 = tf.reduce_sum((params['sigma_k2']-params['sigma_k1'])*params['sigma_s'])*2\n",
    "    t5 = tf.reduce_sum(params['sigma_z']*params['sigma_s'])*2\n",
    "    t6 = tf.reduce_sum(params['sigma_s']**2)\n",
    "    higordder = (t1*Vrr + t2*Vrz + t3*Vzz + t4*Vrs + t5*Vzs + t6*Vss)/2*V\n",
    "    \n",
    "    return logXiE, k1a, k2a, c_root_large, d1_root, d2_root, uu, penalty_term, mu_1, mu_k1, mu_k2, mu_r, zdrift, sdrift, h1, h2, hz, hs, higordder, Vr, Vz, Vs, Vrr, Vzz, Vss, Vrz, Vrs, Vzs\n",
    "    \n",
    "@tf.function \n",
    "def HJB_loss_E(func, W, Z, V, params):\n",
    "    X = tf.concat([W,Z,V], axis=1)\n",
    "    logXiE, k1a, k2a, c_root_large, d1_root, d2_root, uu, penalty_term, mu_1, mu_k1, mu_k2, mu_r, zdrift, sdrift, h1, h2, hz, hs, higordder, Vr, Vz, Vs, Vrr, Vzz, Vss, Vrz, Vrs, Vzs = calvar(func, W, Z, V, params)\n",
    "    HJB = uu + mu_r*Vr + zdrift*Vz + sdrift*Vs + higordder\n",
    "    \n",
    "    return HJB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59520d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_factory(model, loss, valueFunctionLogE, W, Z, V, params, loss_type, targets):\n",
    "\n",
    "    ## Obtain the shapes of all trainable parameters in the model\n",
    "    shapes = tf.shape_n(model.trainable_variables)\n",
    "    n_tensors = len(shapes)\n",
    "\n",
    "    # we'll use tf.dynamic_stitch and tf.dynamic_partition later, so we need to prepare required information first\n",
    "    count = 0\n",
    "    idx = [] # stitch indices\n",
    "    part = [] # partition indices\n",
    "\n",
    "    for i, shape in enumerate(shapes):\n",
    "        n = np.product(shape)\n",
    "        idx.append(tf.reshape(tf.range(count, count+n, dtype=tf.int32), shape))\n",
    "        part.extend([i]*n)\n",
    "        count += n\n",
    "    part = tf.constant(part)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_new_model_parameters(params_1d):\n",
    "        params = tf.dynamic_partition(params_1d, part, n_tensors)\n",
    "        for i, (shape, param) in enumerate(zip(shapes, params)):\n",
    "            model.trainable_variables[i].assign(tf.reshape(param, shape))\n",
    "\n",
    "    # Create a function that will compute the value and gradient. This can be the function that the factory returns\n",
    "    @tf.function\n",
    "    def val_and_grad(params_1d):\n",
    "        with tf.GradientTape() as tape:\n",
    "          ## Update the parameters in the model\n",
    "            assign_new_model_parameters(params_1d)\n",
    "            ## Calculate the loss \n",
    "            loss_value = loss_type(loss(valueFunctionLogE, W, Z, V, params), targets)\n",
    "        ## Calculate gradients and convert to 1D tf.Tensor\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        grads = tf.dynamic_stitch(idx, grads)\n",
    "        del tape\n",
    "\n",
    "        ## Print out iteration & loss\n",
    "        f.iter.assign_add(1)\n",
    "#         tf.print(\"Iter:\", f.iter, \"loss:\", loss_value)\n",
    "\n",
    "        ## Store loss value so we can retrieve later\n",
    "        tf.py_function(f.history.append, inp=[loss_value], Tout=[])\n",
    "\n",
    "        return loss_value, grads\n",
    "\n",
    "    def f(params_1d):\n",
    "      return [vv.numpy().astype(np.float64)  for vv in val_and_grad(params_1d)]\n",
    "\n",
    "    ## Store these information as members so we can use them outside the scope\n",
    "    f.iter = tf.Variable(0)\n",
    "    f.idx = idx\n",
    "    f.part = part\n",
    "    f.shapes = shapes\n",
    "    f.assign_new_model_parameters = assign_new_model_parameters\n",
    "    f.history = []\n",
    "\n",
    "    return f\n",
    "  \n",
    "\n",
    "## Training step BFGS\n",
    "def training_step_BFGS(valueFunctionLogE, W, Z, V, params, targets, maxiter, maxfun, gtol, maxcor, maxls, ftol):\n",
    "\n",
    "  ## Train experts NN\n",
    "  loss_fun = tf.keras.losses.MeanSquaredError()\n",
    "  func_E = function_factory(valueFunctionLogE, HJB_loss_E, valueFunctionLogE, W, Z, V, params, loss_fun, targets)\n",
    "  init_params_E = tf.dynamic_stitch(func_E.idx, valueFunctionLogE.trainable_variables)\n",
    "\n",
    "  start = time.time()\n",
    "  results = optimize.minimize(func_E, x0 = init_params_E.numpy(), method = 'L-BFGS-B', jac = True, options = {'maxiter': maxiter, 'maxfun': maxfun, 'gtol': gtol, 'maxcor': maxcor, 'maxls': maxls, 'ftol' : ftol})\n",
    "  end = time.time()\n",
    "  print('Elapsed time for experts {:.4f} sec'.format(end - start))\n",
    "  # after training, the final optimized parameters are still in results.position\n",
    "  # so we have to manually put them back to the model\n",
    "  func_E.assign_new_model_parameters(results.x)\n",
    "  \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "146f454d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Elapsed time for experts 2.3877 sec\n",
      "0.24569641645547755\n",
      "Iteration 1\n",
      "Elapsed time for experts 0.8599 sec\n",
      "0.0018920977731812494\n",
      "Iteration 2\n",
      "Elapsed time for experts 0.7614 sec\n",
      "0.0007942205380751125\n",
      "Iteration 3\n",
      "Elapsed time for experts 0.8374 sec\n",
      "0.0028153856933303446\n",
      "Iteration 4\n",
      "Elapsed time for experts 0.8204 sec\n",
      "0.0042173939321204865\n",
      "Iteration 5\n",
      "Elapsed time for experts 0.7666 sec\n",
      "0.0005934856804734486\n",
      "Iteration 6\n",
      "Elapsed time for experts 0.7597 sec\n",
      "0.0029446646032359382\n",
      "Iteration 7\n",
      "Elapsed time for experts 0.8322 sec\n",
      "0.0011193587499480095\n",
      "Iteration 8\n",
      "Elapsed time for experts 0.7928 sec\n",
      "0.0003905046288100193\n",
      "Iteration 9\n",
      "Elapsed time for experts 0.7685 sec\n",
      "0.0005501091384049861\n",
      "Iteration 10\n",
      "Elapsed time for experts 0.7852 sec\n",
      "0.0009487088701380287\n",
      "Iteration 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#   W = tf.random.normal(shape = (batchSize,1), mean = 0.0, stddev = 0.5, dtype=tf.float64)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#   Z = tf.random.normal(shape = (batchSize,1), mean = 0.0, stddev = 0.5, dtype=tf.float64)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28miter\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step_BFGS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogXiE_NN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_maxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxfun\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_maxfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_gtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxcor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_maxcor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_maxls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mftol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBFGS_ftol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mfun)\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mfun\u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-11\u001b[39m:\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mtraining_step_BFGS\u001b[0;34m(valueFunctionLogE, W, Z, params, targets, maxiter, maxfun, gtol, maxcor, maxls, ftol)\u001b[0m\n\u001b[1;32m     68\u001b[0m init_params_E \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdynamic_stitch(func_E\u001b[38;5;241m.\u001b[39midx, valueFunctionLogE\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     70\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 71\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_E\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minit_params_E\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxfun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxcor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxcor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mftol\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElapsed time for experts \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/scipy/optimize/optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mfunction_factory.<locals>.f\u001b[0;34m(params_1d)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params_1d):\n\u001b[0;32m---> 49\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [vv\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)  \u001b[38;5;28;01mfor\u001b[39;00m vv \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_1d\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points_size = 1\n",
    "dimension = 3\n",
    "units = 16\n",
    "activation = 'tanh'\n",
    "kernel_initializer = 'glorot_normal'\n",
    "batchSize = 2048 * points_size\n",
    "batchSize = 100\n",
    "iter_num = 50\n",
    "BFGS_maxiter  = 1000\n",
    "BFGS_maxfun   = 1000\n",
    "BFGS_gtol     = 1.0 * np.finfo(float).eps\n",
    "BFGS_maxcor   = 100\n",
    "BFGS_maxls    = 100\n",
    "BFGS_ftol     = 1.0 * np.finfo(float).eps\n",
    "\n",
    "## NN structure\n",
    "tf.keras.backend.set_floatx(\"float64\") ## Use float64 by default\n",
    "\n",
    "# logXiE_NN = tf.keras.Sequential(\n",
    "#     [tf.keras.Input(shape=[dimension,]),\n",
    "#       tf.keras.layers.Dense(units, activation=activation, kernel_initializer=kernel_initializer),\n",
    "#       tf.keras.layers.Dense(units, activation=activation, kernel_initializer=kernel_initializer),\n",
    "# #       tf.keras.layers.Dense(units, activation=activation, kernel_initializer=kernel_initializer),\n",
    "#       tf.keras.layers.Dense(1,  activation= None,  kernel_initializer='glorot_normal')])\n",
    "logXiE_NN = DGMNet(layer_width =16, n_layers = 3, input_dim = 3, final_trans=None)\n",
    "\n",
    "start = time.time()\n",
    "targets = tf.zeros(shape=(batchSize,1), dtype=tf.float64)\n",
    "for iter in range(iter_num):\n",
    "  W = tf.random.uniform(shape = (batchSize,1), minval = params['wMin'], maxval = params['wMax'], dtype=tf.float64)\n",
    "  Z = tf.random.uniform(shape = (batchSize,1), minval = params['zMin'], maxval = params['zMax'], dtype=tf.float64)\n",
    "  V = tf.random.uniform(shape = (batchSize,1), minval = params['vMin'], maxval = params['vMax'], dtype=tf.float64)\n",
    "  print('Iteration', iter)\n",
    "  results = training_step_BFGS(logXiE_NN, W, Z, V, params, targets,\\\n",
    "                    maxiter = BFGS_maxiter, maxfun = BFGS_maxfun, gtol = BFGS_gtol, maxcor = BFGS_maxcor, maxls = BFGS_maxls, ftol = BFGS_ftol)\n",
    "  print(results.fun)\n",
    "  if results.fun< 1e-11:\n",
    "    break\n",
    "end = time.time()\n",
    "training_time = '{:.4f}'.format((end - start)/60)\n",
    "print('Elapsed time for training {:.4f} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40160986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid points for l:  3001\n",
      "grid size for l:  0.0006666666666666666\n",
      "grid points for z:  201\n",
      "grid size for z:  0.01\n"
     ]
    }
   ],
   "source": [
    "lscale = 0.1\n",
    "zscale = 0.1\n",
    "sscale = 1.0\n",
    "llim = 1.0\n",
    "srange = 0.999\n",
    "\n",
    "lgrid = int(1000*lscale+1)\n",
    "print('grid points for l: ', lgrid)\n",
    "rscale = llim*2/(lgrid-1)\n",
    "print('grid size for l: ', rscale)\n",
    "\n",
    "zgrid = int(200*zscale+1)\n",
    "print('grid points for z: ', zgrid)\n",
    "zscale = 2/(zgrid-1)\n",
    "print('grid size for z: ', zscale)\n",
    "\n",
    "sgrid = int(20*sscale+1)\n",
    "print('grid points for s: ', sgrid)\n",
    "sscale = 2*srange/(sgrid-1)\n",
    "print('grid size for s: ', sscale)\n",
    "\n",
    "ll = np.linspace(-llim,llim,lgrid)\n",
    "zz = np.linspace(-1,1,zgrid)\n",
    "ss = np.linspace(-srange+1,srange+1,sgrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb28b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logXiE, k1a, k2a, c_root_large, d1_root, d2_root, uu, penalty_term, mu_1, mu_k1, mu_k2, mu_r, zdrift, sdrift, h1, h2, hz, hs, higordder, Vr, Vz, Vs, Vrr, Vzz, Vss, Vrz, Vrs, Vzs\\\n",
    "= calvar(logXiE_NN, np.linspace(-1,1,batchSize).reshape([batchSize,1]), np.zeros([batchSize,1]), np.ones([batchSize,1]), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b657d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('/project/lhansen/twocapstk/output/twocap_stk_111_all_cov_demean/llim_1.0_lscale_0.1_zscale_0.1/sscale_1.0_srange_0.999/kappa_'+str(kappa.numpy())+'_zeta_'+str(zeta.numpy())+\\\n",
    "        '/gamma_'+str(gamma.numpy())+'_rho_'+str(rho.numpy())+'/model_sym_5.0e-5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f14e5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/software/python-anaconda-2022.05-el8-x86_64/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,6))\n",
    "sns.lineplot(np.linspace(-1,1,batchSize),c_root_large.numpy().flatten(),label = \"NN\")\n",
    "sns.lineplot(np.linspace(-1,1,lgrid),npz['cons'][:,10,10],label = \"FDM\")\n",
    "\n",
    "ax.set_ylim([-0.01,0.3])\n",
    "ax.set_ylabel(r'$c$')\n",
    "ax.set_xlabel(r'$\\hat{y}$')\n",
    "ax.set_title(r'c, '+ '$\\gamma=$'+str(gamma.numpy())+', '+'$\\\\rho$'+'='+str(rho.numpy())+', '+'$\\\\kappa$'+'='+str(kappa.numpy()))\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "# fig.savefig(figname+'/con.png', dpi = 400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
